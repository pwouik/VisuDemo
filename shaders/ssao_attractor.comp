#version 460 core
layout (local_size_x = 32, local_size_y = 32, local_size_z = 1) in;
layout(rgba32f, binding = 0) uniform image2D target;
layout(r32i, binding = 1) uniform iimage2D depth;
layout(r32f, binding = 4) uniform image2D jumpdist; //texture that store jump distances
uniform mat4 inv_proj;
uniform uvec2 screen_size;

#define PI 3.14159265358
mat2 inv_proj_small;


//map range for jumpdistance
// #define JD_FR_MIN 0
// #define JD_FR_MAX 1
// #define JD_TO_MIN 0
// #define JD_TO_MAX 1

//remove and replace by above when nice value found
uniform float JD_FR_MIN;
uniform float JD_FR_MAX;
uniform float JD_TO_MIN;
uniform float JD_TO_MAX;


float d, dnx, dny, dpx, dpy; //distance 
vec3 wco, wconx, wcony, wcopx, wcopy; // world coordinate
vec3 ssnormal;

float sampleDepth(ivec2 pos){
    vec2 prod  = inv_proj_small * vec2(float(imageLoad(depth,pos).r)/(1<<31),1);
    return prod.x / prod.y * inv_proj[0].x * screen_size.x/2;
}

float sampleJumpDist(ivec2 pos){
    float jd = imageLoad(jumpdist, pos).r;
    return (jd-JD_FR_MIN)/(JD_FR_MAX-JD_FR_MIN) * (JD_TO_MAX-JD_TO_MIN) + JD_TO_MIN;
}

//thanks gpt
vec3 getWorldPosition(ivec2 pos) {
    float z = float(imageLoad(depth, pos).r) / (1 << 31);

    // Convert from screen space to normalized device coordinates (NDC)
    vec2 ndc = vec2(pos) / screen_size * 2.0 - 1.0;

    // Form the clip space position
    vec4 clipSpacePos = vec4(ndc, z, 1.0);

    // Unproject to world space
    vec4 worldSpacePos = inv_proj * clipSpacePos;

    //perspective divide
    worldSpacePos /= worldSpacePos.w;

    return worldSpacePos.xyz; // Return the 3D world position
}

void computeNormals(){
    wco = getWorldPosition(ivec2(gl_GlobalInvocationID.xy));
    wconx = getWorldPosition(ivec2(gl_GlobalInvocationID.xy)-ivec2(1,0));
    wcopx = getWorldPosition(ivec2(gl_GlobalInvocationID.xy)+ivec2(1,0));
    wcony = getWorldPosition(ivec2(gl_GlobalInvocationID.xy)-ivec2(0,1));
    wcopy = getWorldPosition(ivec2(gl_GlobalInvocationID.xy)+ivec2(0,1));

    vec3 up = normalize(wcopy-wco);
    vec3 down = normalize(wcony-wco);
    vec3 right = normalize(wcopx-wco);
    vec3 left = normalize(wconx-wco);

    ssnormal = (cross(up,right) + cross(right, down) + cross(down, left), + cross(left, up))/4;
}

void main() {
    // Check if the current thread is within the bounds of the screen
    if (gl_GlobalInvocationID.x>=screen_size.x || gl_GlobalInvocationID.y>=screen_size.y)
        return;

    inv_proj_small = mat2(inv_proj[2].zw,inv_proj[3].zw);

    d = sampleDepth(ivec2(gl_GlobalInvocationID.xy));
    dnx = sampleDepth(ivec2(gl_GlobalInvocationID.xy)-ivec2(1,0));
    dpx = sampleDepth(ivec2(gl_GlobalInvocationID.xy)+ivec2(1,0));
    dny = sampleDepth(ivec2(gl_GlobalInvocationID.xy)-ivec2(0,1));
    dpy = sampleDepth(ivec2(gl_GlobalInvocationID.xy)+ivec2(0,1));

    float c = 1-(atan(dnx-d)+atan(dpx-d)+atan(dny-d)+atan(dpy-d))/(PI*2);
    
    float dj =  sampleJumpDist(ivec2(gl_GlobalInvocationID.xy));
    //imageStore(target, ivec2(gl_GlobalInvocationID.xy), vec4(c,(c+dj)/2,dj,1));

    //debug
    computeNormals();
    imageStore(target, ivec2(gl_GlobalInvocationID.xy), vec4(abs(ssnormal.xyz),1));
}